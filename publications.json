[
  {
    "title": "MetaDragonBoat: Exploring Paddling Techniques of Virtual Dragon Boating in a Metaverse Campus",
    "authors": "W He, X Li, S Xu, <span class=\"custom-bold\">Y Chen</span>, CI Sio, GL Kan, LH Lee (SIGMM '24)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_meta_dragon_boat.jpg",
    "abstract": "The preservation of cultural heritage, as mandated by the United Nations Sustainable Development Goals (SDGs), is integral to sustainable urban development. This paper focuses on the Dragon Boat Festival, a prominent event in Chinese cultural heritage, and proposes leveraging Virtual Reality (VR), to enhance its preservation and accessibility. Traditionally, participation in the festival's dragon boat races was limited to elite athletes, excluding broader demographics. Our proposed solution, named MetaDragonBoat, enables virtual participation in dragon boat racing, offering immersive experiences that replicate physical exertion through a cultural journey. Thus, we build a digital twin of a university campus located in a region with a rich dragon boat racing tradition. Coupled with three paddling techniques that are enabled by either commercial controllers or physical paddle controllers with haptic feedback, diversified users can engage in realistic rowing experiences. Our results demonstrate that by integrating resistance into the paddle controls, users could simulate the physical effort of dragon boat racing, promoting a deeper understanding and appreciation of this cultural heritage.",
    "//remark": "üèÖ Honorable Mention Award at CHI 2024"
  },
  {
    "title": "Hearing the Moment with MetaEcho! From Physical to Virtual in Synchronized Sound Recording",
    "authors": "Z Wei, <span class=\"custom-bold\">Y Chen</span>, W Tong, X Zong, H Qu, X Xu, LH Lee (SIGMM '24)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_meta_echo.png",
    "abstract": "In film education, high expenses and limited space significantly challenge teaching synchronized sound recording (SSR). Traditional methods, which emphasize theory with limited practical experience, often fail to bridge the gap between theoretical understanding and practical application. As such, we introduce MetaEcho, an educational virtual reality leveraging the presence theory for teaching SSR. MetaEcho provides realistic simulations of various recording equipment and facilitates communication between learners and instructors, offering an immersive learning experience that closely mirrors actual practices. An evaluation with 24 students demonstrated that MetaEcho surpasses the traditional method in presence, collaboration, usability, realism, comprehensibility, and creativity. Three experts also commented on the benefits of MetaEcho and the opportunities for promoting SSR education in the metaverse era."
  },
  {
    "title": "GesMessages: Using Mid-air Gestures to Manage Notifications",
    "authors": "X Li, <span class=\"custom-bold\">Y Chen</span>, X Tang (SUI '23 Poster)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_gesmes.png",
    "abstract": "This paper introduces GesMessages, an innovative mid-air interactive application that uses simple gestures to manage real-time message notifications on laptops and large displays. Leveraging cameras on computers or smart devices, the application offers three distinct gestures: expanding notifications for immediate attention, hiding non-urgent messages, and deleting spam messages. We present the technical setup and system design. Additionally, we explore potential applications in context-awareness systems, contributing to gestural interaction research. Our work fosters a deeper understanding of mid-air interaction‚Äôs impact on message management and future interactive systems."
  },
  {
    "title": "Dragon Boat Simulation: An Immersive Experience Beyond Traditional Gaming",
    "authors": "W He, <span class=\"custom-bold\">Y Chen</span>, S Xu, C Ding, LH Lee, GL Kan (SUI '23 Poster)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_dragon_boat_poster.png",
    "abstract": "Immersive sports are emerging recently after the metaverse hype. This paper investigates an immersive setup that leverages virtual reality to recreate the kinetic and sensory nuances of dragon boating. We employ a body-centric approach to enable users to engage with authentic paddling actions, e.g., mobilising iron sticks on the boat with reasonably emulated water resistance. The virtual environments mirror real-world scenes, e.g., Pearl River (Guangdong). We employed multi-modal experiences to replicate the visuals and tactile, kinesthetic, and environmental intricacies of dragon boating. Our Dragon Boat simulator serves as a groundwork for redefining the boundaries of immersive sports training that bridges the gap between virtuality and the real world."
  },
  {
    "title": "Auto-Paizo Games: Towards Understanding the Design of Games That Aim to Unify a Player‚Äôs Physical Body and the Virtual World",
    "authors": "R Patibanda, C Hill, A Saini, X Li, <span class=\"custom-bold\">Y Chen</span>, A Matviienko, J Knibbe, E van den Hoven, FF Mueller (CHI Play '23)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_auto_paizo.png",
    "abstract": "Most digital bodily games focus on the body as they use movement as input. However, they also draw the player‚Äôs focus away from the body as the output occurs on visual displays, creating a divide between the physical body and the virtual world. We propose a novel approach ‚Äì the \"Body as a Play Material\" ‚Äì where a player uses their body as both input and output to unify the physical body and the virtual world. To showcase this approach, we designed three games where a player uses one of their hands (input) to play against the other hand (output) by loaning control over its movements to an Electrical Muscle Stimulation (EMS) system. We conducted a thematic analysis on the data obtained from a field study with 12 participants to articulate four player experience themes. We discuss our results about how participants appreciated the engagement with the variety of bodily movements for play and the ambiguity of using their body as a play material. Ultimately, our work aims to unify the physical body and the virtual world."
  },
  {
    "title": "Fused Spectatorship: Designing Bodily Experiences Where Spectators Become Players",
    "authors": "R Patibanda, A Saini, N Overdevest, MF Montoya, X Li, <span class=\"custom-bold\">Y Chen</span>, S Nisal, J Andres, J Knibbe, E van den Hoven, FF Mueller (CHI Play '23)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_fused_spectatorship.png",
    "abstract": "Spectating digital games can be exciting. However, due to its vicarious nature, spectators often wish to engage in the gameplay beyond just watching and cheering. To blur the boundaries between spectators and players, we propose a novel approach called \"Fused Spectatorship\", where spectators watch their hands play games by loaning bodily control to a computational Electrical Muscle Stimulation (EMS) system. To showcase this concept, we designed three games where spectators loan control over both their hands to the EMS system and watch them play these competitive and collaborative games. A study with 12 participants suggested that participants could not distinguish if they were watching their hands play, or if they were playing the games themselves. We used our results to articulate four spectator experience themes and four fused spectator types, the behaviours they elicited and offer one design consideration to support each of these behaviours. We also discuss the ethical design considerations of our approach to help game designers create future fused spectatorship experiences."
  },
  {
    "title": "GesPlayer: Using Augmented Gestures to Empower Video Players",
    "authors": "X Li, <span class=\"custom-bold\">Y Chen</span>, X Tang (ISS '22 Poster)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_gesplayer.png",
    "abstract": "In this paper, we introduce GesPlayer, a gesture-based empowered video player that explores how users can experience their hands as an interface through gestures. We provide three semantic gestures based on the camera of a computer or other smart device to detect and adjust the progress of video playback, volume, and screen brightness, respectively. Our goal is to enable users to control video playback simply by their gestures in the air, without the need to use a mouse or keyboard, especially when it is not convenient to do so. Ultimately, we hope to expand our understanding of gesture-based interaction by understanding the inclusiveness of designing the hand as an interactive interface, and further broaden the state of semantic gestures in an interactive environment through computational interaction methods."
  },
  {
    "title": "Actuating Myself: Designing Hand-Games Incorporating Electrical Muscle Stimulation",
    "authors": "R Patibanda, X Li, <span class=\"custom-bold\">Y Chen</span>, A Saini, CN Hill, E van den Hoven, FF Mueller (CHI Play '21)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_actuating_myself.png",
    "abstract": "Motor movements are performed while playing hand-games such as Rock-paper-scissors or Thumb-war. These games are believed to benefit both physical and mental health and are considered cultural assets. Electrical Muscle Stimulation (EMS) is a technology that can actuate muscles, triggering motor movements and hence offers an opportunity for novel play experiences based on these traditional hand-games. However, there is only limited understanding of the design of EMS games. We present the design and evaluation of two games inspired by traditional hand-games, ‚ÄùSlap-me-if-you-can‚Äù and ‚Äù3-4-5‚Äù, which incorporate EMS and can be played alone, unlike traditional games. A thematic analysis of the data collected revealed three themes: 1) Gameplay experiences and influence of EMS hardware, 2) Interaction with EMS and the calibration process and, 3) Shared control and its effect on playing EMS games. We hope that an enhanced understanding of the potential of EMS to support hand-games can aid the advancement of movement-based games as a whole."
  },
  {
    "title": "vrCAPTCHA: exploring CAPTCHA designs in virtual reality",
    "authors": "X Li, <span class=\"custom-bold\">Y Chen</span>, R Patibanda, FF Mueller (CHI Play '21)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_vrcaptcha.png",
    "abstract": "With the popularity of online access in virtual reality (VR) devices, it will become important to investigate exclusive and interactive CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart) designs for VR devices. In this paper, we first present four traditional two-dimensional (2D) CAPTCHAs (i.e., text-based, image-rotated, image-puzzled, and image-selected CAPTCHAs) in VR. Then, based on the three-dimensional (3D) interaction characteristics of VR devices, we propose two vrCAPTCHA design prototypes (i.e., task-driven and bodily motion-based CAPTCHAs). We conducted a user study with six participants for exploring the feasibility of our two vrCAPTCHAs and traditional CAPTCHAs in VR. We believe that our two vrCAPTCHAs can be an inspiration for the further design of CAPTCHAs in VR."
  },
  {
    "title": "Exploration of hands-free text entry techniques for virtual reality",
    "authors": "X Lu, D Yu, HN Liang, W Xu, <span class=\"custom-bold\">Y Chen</span>, X Li, K Hasan (ISMAR '20)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_hands-free_input.png",
    "abstract": "Text entry is a common activity in virtual reality (VR) systems. There is a limited number of available hands-free techniques, which allow users to carry out text entry when users‚Äô hands are busy such as holding items or hand-based devices are not available. The most used hands-free text entry technique is DwellType, where a user selects a letter by dwelling over it for a specific period. However, its performance is limited due to the fixed dwell time for each character selection. In this paper, we explore two other hands-free text entry mechanisms in VR: BlinkType and NeckType, which leverage users‚Äô eye blinks and neck‚Äôs forward and backward movements to select letters. With a user study, we compare the performance of the two techniques with DwellType. Results show that users can achieve an average text entry rate of 13.47, 11.18 and 11.65 words per minute with BlinkType, NeckType, and DwellType, respectively. Users‚Äô subjective feedback shows BlinkType as the preferred technique for text entry in VR."
  },
  {
    "title": "Auto-Hierarchical Data Algorithm: Focus on Increasing Users‚Äô Motivation and Duration In Virtual Reality",
    "authors": "X Li, <span class=\"custom-bold\">Y Chen</span> (ICBDA '20)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_auto_hierarchical.png",
    "abstract": "Virtual reality (VR) exergames have become part of increasingly popular serious games because of both the fast development of VR technology and diversified dissemination of exergames. In this paper, we designed a built-in algorithm which based on the fatigue parameter to timely adjust the exergame's difficulty, especially in body-building/fitness exercise. The calculation method of fatigue index is obtained by using analytic hierarchy process (AHP) with six influencing factors: (1) average Heart Rate (avgHR); (2) Borg CR 6-20; (3) Calorie(s); (4) Accuracy Rate (Acc%); (5) Intensity; (6) Exercise time. Result from the experiments with 8 participants shows that the fitness exergame sorted by the auto-hierarchical algorithm we designed will be more effective than the traditional process by partly increasing both users' motivation and duration of playing exergame in the current phase."
  },
  {
    "title": "Exploring Visual Techniques for Boundary Awareness During Interaction in Augmented Reality Head-Mounted Displays",
    "authors": "W Xu, HN Liang, <span class=\"custom-bold\">Y Chen</span>, X Li, K Yu (IEEE VR '20)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_boundary_awareness.png",
    "abstract": "Mid-air hand interaction has long been proposed as a ‚Äònatural‚Äô input method for Augmented Reality (AR) systems. Current AR Head-Mounted Displays (HMDs) have a limited area for hand-based interactions. Because of this, users may easily move their hand(s) outside this tracked area during interaction, especially in dynamic tasks (e.g., when translating an object). Compared to common midair interaction issues, such as gesture recognition, arm/hand fatigue, and unnatural ways of interacting with virtual objects (e.g., selecting a distant object), boundary awareness issues in AR devices have received little attention. In this research, we explore visual techniques for boundary awareness in AR HMDs, focusing on object translation tasks. Through a systematic formative study, we first identify the challenges that users might face when interacting with AR HMDs without any boundary awareness information (i.e., how current systems work). Based on the findings, we then propose four methods (i.e., static surfaces, dynamic surface(s), static coordinated lines, and dynamic coordinate line(s)) and evaluate them against the benchmark (i.e., baseline condition without boundary awareness) to make users aware of the tracked interaction area. Our results show that visual methods for boundary awareness can help with dynamic mid-air hand interactions in AR HMDs, but their effectiveness and application are user-dependent."
  },
  {
    "title": "Results and Guidelines From a Repeated-Measures Design Experiment Comparing Standing and Seated Full-Body Gesture-Based Immersive Virtual Reality Exergames: Within-Subjects Evaluation",
    "authors": "W Xu, HN Liang, Q He, X Li, K Yu, <span class=\"custom-bold\">Y Chen</span> (JMIR '20)",
    "pdfLink": "#",
    "videoLink": "#",
    "doiLink": "#",
    "imageSrc": "images/teaser_full-body.png",
    "abstract": "Seated exercises are common in various settings, but they are rarely adapted into seated exergames. While immersive virtual reality (iVR) exergames typically focus on standing full-body gestures, the potential of seated exergames remains underexplored. This study compared gameplay performance, intrinsic motivation, and motion sickness between standing and seated full-body gesture-based iVR exergames. Fifty-two participants played both game modes in a counterbalanced order, with metrics including gesture completion time, missed gestures, heart rate, perceived exertion, intrinsic motivation, motion sickness, and fear of falling. Results showed that players missed more gestures in the seated exergame, but seated play also led to higher exertion, as indicated by increased heart rate, calories burned, and Borg scale scores (all P<.001). Seated play was associated with higher peripheral and sopite-related motion sickness (P=.02 and P=.004), though there were no significant differences in intrinsic motivation or fear of falling between modes. These findings suggest that seated iVR exergames provide greater exertion and value for players and may be better suited for small spaces, but careful gesture design is needed to mitigate motion sickness."
  }
]
